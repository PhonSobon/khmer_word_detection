{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "132f62a6",
   "metadata": {},
   "source": [
    "### CELL 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68608c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ultralytics (YOLOv8)\n",
    "!pip install ultralytics opencv-python matplotlib pillow pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f9bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import yaml\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from IPython.display import Image, display\n",
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "\n",
    "print(\"✓ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c169c7",
   "metadata": {},
   "source": [
    "### CELL 2: Setup Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3badd45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"dataset\"\n",
    "DATA_YAML = os.path.join(DATASET_PATH, \"data.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adbc060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "MODEL_NAME = \"yolov8m.pt\"\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = 640\n",
    "DEVICE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10527c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "OUTPUT_DIR = \"runs/detect/khmer_text_detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fdea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Dataset: {DATASET_PATH}\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  Image Size: {IMAGE_SIZE}\")\n",
    "print(f\"  Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766c827e",
   "metadata": {},
   "source": [
    "### CELL 3: Verify Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1e3c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_dataset(dataset_path, data_yaml):\n",
    "    \"\"\"Verify dataset structure and files\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"DATASET VERIFICATION\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Check if data.yaml exists\n",
    "    if not os.path.exists(data_yaml):\n",
    "        print(f\"Error: {data_yaml} not found!\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"Found data.yaml\")\n",
    "    \n",
    "    # Load data.yaml\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    \n",
    "    print(f\"\\nDataset configuration:\")\n",
    "    print(f\"  Path: {data.get('path', 'Not specified')}\")\n",
    "    print(f\"  Classes: {data.get('names', {})}\")\n",
    "    \n",
    "    # Check splits\n",
    "    splits = ['train', 'val', 'test']\n",
    "    for split in splits:\n",
    "        img_dir = os.path.join(dataset_path, split, 'images')\n",
    "        label_dir = os.path.join(dataset_path, split, 'labels')\n",
    "        \n",
    "        if os.path.exists(img_dir) and os.path.exists(label_dir):\n",
    "            img_count = len([f for f in os.listdir(img_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "            label_count = len([f for f in os.listdir(label_dir) if f.endswith('.txt')])\n",
    "            print(f\"\\n  {split.upper()}:\")\n",
    "            print(f\"    Images: {img_count}\")\n",
    "            print(f\"    Labels: {label_count}\")\n",
    "            \n",
    "            if img_count != label_count:\n",
    "                print(f\"Warning: Image and label counts don't match!\")\n",
    "        else:\n",
    "            print(f\"\\n  {split.upper()}: Directory not found\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc7e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run verification\n",
    "verify_dataset(DATASET_PATH, DATA_YAML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64839054",
   "metadata": {},
   "source": [
    "### CELL 4: Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e101021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(dataset_path, num_samples=4):\n",
    "    \"\"\"Visualize random samples with bounding boxes\"\"\"\n",
    "    import random\n",
    "    \n",
    "    train_img_dir = os.path.join(dataset_path, 'train', 'images')\n",
    "    train_label_dir = os.path.join(dataset_path, 'train', 'labels')\n",
    "    \n",
    "    # Get random images\n",
    "    images = [f for f in os.listdir(train_img_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    samples = random.sample(images, min(num_samples, len(images)))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, img_name in enumerate(samples):\n",
    "        # Read image\n",
    "        img_path = os.path.join(train_img_dir, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Read labels\n",
    "        label_name = Path(img_name).stem + '.txt'\n",
    "        label_path = os.path.join(train_label_dir, label_name)\n",
    "        \n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            h, w = img.shape[:2]\n",
    "            \n",
    "            # Draw bounding boxes\n",
    "            for line in lines[:50]:  # Limit to 50 boxes for visualization\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id, x_center, y_center, width, height = map(float, parts[:5])\n",
    "                    \n",
    "                    # Convert YOLO format to pixel coordinates\n",
    "                    x1 = int((x_center - width/2) * w)\n",
    "                    y1 = int((y_center - height/2) * h)\n",
    "                    x2 = int((x_center + width/2) * w)\n",
    "                    y2 = int((y_center + height/2) * h)\n",
    "                    \n",
    "                    # Draw rectangle\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            \n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].set_title(f'{img_name}\\n{len(lines)} words')\n",
    "            axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'sample_images.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"✓ Saved visualization to {OUTPUT_DIR}/sample_images.png\")\n",
    "\n",
    "visualize_samples(DATASET_PATH, num_samples=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e168809",
   "metadata": {},
   "source": [
    "### CELL 5: Initialize YOLOv8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba7295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained YOLOv8 model\n",
    "model = YOLO(MODEL_NAME)\n",
    "\n",
    "print(f\"✓ Loaded {MODEL_NAME} model\")\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(model.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716d6e98",
   "metadata": {},
   "source": [
    "### CELL 6: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22589fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=DATA_YAML,\n",
    "    epochs=EPOCHS,\n",
    "    batch=BATCH_SIZE,\n",
    "    imgsz=IMAGE_SIZE,\n",
    "    device=DEVICE,\n",
    "    project='runs/detect',\n",
    "    name='khmer_text_detection',\n",
    "    patience=20,  # Early stopping patience\n",
    "    save=True,\n",
    "    save_period=10,  # Save checkpoint every 10 epochs\n",
    "    cache=False,  # Set to True to cache images for faster training (requires more RAM)\n",
    "    pretrained=True,\n",
    "    optimizer='AdamW',\n",
    "    verbose=True,\n",
    "    seed=42,\n",
    "    deterministic=True,\n",
    "    single_cls=True,  # Single class (word)\n",
    "    rect=False,\n",
    "    cos_lr=True,  # Cosine learning rate scheduler\n",
    "    close_mosaic=10,  # Disable mosaic augmentation for last N epochs\n",
    "    resume=False,  # Resume from last checkpoint\n",
    "    amp=True,  # Automatic Mixed Precision\n",
    "    fraction=1.0,  # Use 100% of dataset\n",
    "    profile=False,\n",
    "    freeze=None,  # Freeze layers\n",
    "    # Data augmentation\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    degrees=0.0,\n",
    "    translate=0.1,\n",
    "    scale=0.5,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    mosaic=1.0,\n",
    "    mixup=0.0,\n",
    "    copy_paste=0.0\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43073953",
   "metadata": {},
   "source": [
    "### CELL 7: Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236ca457",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Validate on validation set\n",
    "val_results = model.val()\n",
    "\n",
    "print(f\"\\nValidation Results:\")\n",
    "print(f\"  mAP50: {val_results.box.map50:.4f}\")\n",
    "print(f\"  mAP50-95: {val_results.box.map:.4f}\")\n",
    "print(f\"  Precision: {val_results.box.mp:.4f}\")\n",
    "print(f\"  Recall: {val_results.box.mr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511dcfe6",
   "metadata": {},
   "source": [
    "### CELL 8: Visualize Training Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81abce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_results(results_dir):\n",
    "    \"\"\"Plot training metrics\"\"\"\n",
    "    results_csv = os.path.join(results_dir, 'results.csv')\n",
    "    \n",
    "    if not os.path.exists(results_csv):\n",
    "        print(f\"Results file not found: {results_csv}\")\n",
    "        return\n",
    "    \n",
    "    # Read results\n",
    "    df = pd.read_csv(results_csv)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Loss\n",
    "    axes[0, 0].plot(df['epoch'], df['train/box_loss'], label='Train Box Loss', marker='o')\n",
    "    axes[0, 0].plot(df['epoch'], df['train/cls_loss'], label='Train Class Loss', marker='s')\n",
    "    axes[0, 0].plot(df['epoch'], df['train/dfl_loss'], label='Train DFL Loss', marker='^')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].set_title('Training Losses')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Plot 2: mAP\n",
    "    if 'metrics/mAP50(B)' in df.columns:\n",
    "        axes[0, 1].plot(df['epoch'], df['metrics/mAP50(B)'], label='mAP@0.5', marker='o', color='green')\n",
    "        axes[0, 1].plot(df['epoch'], df['metrics/mAP50-95(B)'], label='mAP@0.5:0.95', marker='s', color='blue')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('mAP')\n",
    "        axes[0, 1].set_title('Mean Average Precision')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True)\n",
    "    \n",
    "    # Plot 3: Precision and Recall\n",
    "    if 'metrics/precision(B)' in df.columns:\n",
    "        axes[1, 0].plot(df['epoch'], df['metrics/precision(B)'], label='Precision', marker='o', color='purple')\n",
    "        axes[1, 0].plot(df['epoch'], df['metrics/recall(B)'], label='Recall', marker='s', color='orange')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Score')\n",
    "        axes[1, 0].set_title('Precision and Recall')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True)\n",
    "    \n",
    "    # Plot 4: Learning Rate\n",
    "    if 'lr/pg0' in df.columns:\n",
    "        axes[1, 1].plot(df['epoch'], df['lr/pg0'], label='Learning Rate', marker='o', color='red')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Learning Rate')\n",
    "        axes[1, 1].set_title('Learning Rate Schedule')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, 'training_metrics.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Saved training metrics to {results_dir}/training_metrics.png\")\n",
    "\n",
    "# Plot results\n",
    "results_dir = 'runs/detect/khmer_text_detection'\n",
    "plot_training_results(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e85532",
   "metadata": {},
   "source": [
    "### CELL 9: Display Confusion Matrix and Other Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f39e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix\n",
    "confusion_matrix_path = os.path.join(results_dir, 'confusion_matrix.png')\n",
    "if os.path.exists(confusion_matrix_path):\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    display(Image(filename=confusion_matrix_path, width=600))\n",
    "else:\n",
    "    print(\"Confusion matrix not found\")\n",
    "\n",
    "# Display F1 curve\n",
    "f1_curve_path = os.path.join(results_dir, 'F1_curve.png')\n",
    "if os.path.exists(f1_curve_path):\n",
    "    print(\"\\nF1 Score Curve:\")\n",
    "    display(Image(filename=f1_curve_path, width=600))\n",
    "\n",
    "# Display PR curve\n",
    "pr_curve_path = os.path.join(results_dir, 'PR_curve.png')\n",
    "if os.path.exists(pr_curve_path):\n",
    "    print(\"\\nPrecision-Recall Curve:\")\n",
    "    display(Image(filename=pr_curve_path, width=600))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f17cc15",
   "metadata": {},
   "source": [
    "### CELL 10: Test on Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d52cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_samples(model, dataset_path, num_samples=6, conf_threshold=0.25):\n",
    "    \"\"\"Test model on validation samples\"\"\"\n",
    "    val_img_dir = os.path.join(dataset_path, 'val', 'images')\n",
    "    \n",
    "    # Get random images\n",
    "    images = [f for f in os.listdir(val_img_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    samples = random.sample(images, min(num_samples, len(images)))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, img_name in enumerate(samples):\n",
    "        img_path = os.path.join(val_img_dir, img_name)\n",
    "        \n",
    "        # Run prediction\n",
    "        results = model.predict(img_path, conf=conf_threshold, verbose=False)\n",
    "        \n",
    "        # Plot results\n",
    "        result_img = results[0].plot()\n",
    "        result_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        num_detections = len(results[0].boxes)\n",
    "        \n",
    "        axes[idx].imshow(result_img)\n",
    "        axes[idx].set_title(f'{img_name}\\nDetections: {num_detections}')\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, 'validation_predictions.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Saved predictions to {results_dir}/validation_predictions.png\")\n",
    "\n",
    "import random\n",
    "test_on_samples(model, DATASET_PATH, num_samples=6, conf_threshold=0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdc142d",
   "metadata": {},
   "source": [
    "### CELL 11: Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eaed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"EXPORTING MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get best model path\n",
    "best_model_path = os.path.join(results_dir, 'weights', 'best.pt')\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    # Load best model\n",
    "    best_model = YOLO(best_model_path)\n",
    "    \n",
    "    # Export to ONNX format (for deployment)\n",
    "    onnx_path = best_model.export(format='onnx')\n",
    "    print(f\"✓ Exported to ONNX: {onnx_path}\")\n",
    "    \n",
    "    # Export to TorchScript (for PyTorch deployment)\n",
    "    torchscript_path = best_model.export(format='torchscript')\n",
    "    print(f\"✓ Exported to TorchScript: {torchscript_path}\")\n",
    "    \n",
    "    print(f\"\\nModel weights saved at:\")\n",
    "    print(f\"  Best: {best_model_path}\")\n",
    "    print(f\"  Last: {os.path.join(results_dir, 'weights', 'last.pt')}\")\n",
    "else:\n",
    "    print(f\"Best model not found at {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c8affa",
   "metadata": {},
   "source": [
    "### CELL 12: Inference on Custom Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac850cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_image(model_path, image_path, conf_threshold=0.25, save_path=None):\n",
    "    \"\"\"Run inference on a single image\"\"\"\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    # Run prediction\n",
    "    results = model.predict(image_path, conf=conf_threshold, verbose=True)\n",
    "    \n",
    "    # Plot results\n",
    "    result_img = results[0].plot()\n",
    "    result_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(result_img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Detections: {len(results[0].boxes)} words')\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"✓ Saved prediction to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print detection details\n",
    "    print(f\"\\nDetection Details:\")\n",
    "    for i, box in enumerate(results[0].boxes):\n",
    "        conf = box.conf[0].item()\n",
    "        cls = int(box.cls[0].item())\n",
    "        xyxy = box.xyxy[0].tolist()\n",
    "        print(f\"  Box {i+1}: Class={cls}, Confidence={conf:.3f}, BBox={xyxy}\")\n",
    "\n",
    "# Example usage (replace with your image path)\n",
    "# predict_on_image(\n",
    "#     model_path=best_model_path,\n",
    "#     image_path='path/to/your/test_image.png',\n",
    "#     conf_threshold=0.25,\n",
    "#     save_path=os.path.join(results_dir, 'custom_prediction.png')\n",
    "# )\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✓ Training notebook complete!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"  1. Check results in: {results_dir}\")\n",
    "print(f\"  2. Use best model: {best_model_path}\")\n",
    "print(f\"  3. Run inference on new images using the predict_on_image() function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbc988d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
